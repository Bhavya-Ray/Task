{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a00a55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def scrape_election_results(url, table_class):\n",
    "    # Make a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "    data = []\n",
    "\n",
    "    try:\n",
    "        # Check if the request was successful (status code 200)\n",
    "        if response.status_code == 200:\n",
    "            # Parse the HTML content of the page\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            # Find the table with the results\n",
    "            table = soup.find('table', {'class': table_class})\n",
    "\n",
    "            # Extract table headers\n",
    "            headers = [header.get_text(strip=True) for header in table.find('thead').find_all('th')]\n",
    "            headers.append('Link')  # Add a new header for the links\n",
    "\n",
    "            # Extract table rows\n",
    "            rows = table.find('tbody').find_all('tr')\n",
    "            for row in rows:\n",
    "                cols = row.find_all('td')\n",
    "                row_data = {headers[i]: cols[i].get_text(strip=True) for i in range(len(headers) - 1)}\n",
    "\n",
    " # Check for anchor tags and add the link to the row data\n",
    "                for col in cols:\n",
    "                    link_tag = col.find('a')\n",
    "                    if link_tag:\n",
    "                        row_data['Link'] = link_tag['href']\n",
    "                        break  # Assuming one link per row, break after finding the first link\n",
    "\n",
    "                else:\n",
    "                    row_data['Link'] = None  # If no link is found, set to None\n",
    "\n",
    "                data.append(row_data)\n",
    "\n",
    "            # Create DataFrame from the data\n",
    "            df = pd.DataFrame(data)\n",
    "            df['Link']= row_data['Link']='https://results.eci.gov.in/PcResultGenJune2024/'+df['Link']\n",
    "            return df\n",
    "        else:\n",
    "            print(f\"Failed to retrieve the webpage. Status code: {response.status_code}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
